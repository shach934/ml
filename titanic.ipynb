{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Framework\n",
    "* **Define the Problem.** \n",
    "* **Gather Data**\n",
    "* **Prepare Data for Consumptipon** clean data, from raw data to manageable.\n",
    "* **Perform Exploratory Analysis**, explore, understand, look for patterns, problems, classifications, correlations, comparisions. \n",
    "* **Model Data** ML algorithms to learn the data\n",
    "* **Validate&Implement Data Model** \n",
    "* **Optimize**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Using the Passenger information to predict their survival in the Titanic tragedy ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training set and evaluation data set. \n",
    "data_raw = pd.read_csv(\"./data/train.csv\")\n",
    "data_val = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before start to manipulate the original data, deep copy and play on the new dataframe. \n",
    "data1 = data_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Number of passangers and properties:  (891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: \", data1.columns)\n",
    "print(\"Number of passangers and properties: \", data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassengerId => 乘客ID\n",
    "\n",
    "Survived => 是否存活\n",
    "\n",
    "Pclass => 乘客等级(1/2/3等舱位)\n",
    "\n",
    "Name => 乘客姓名\n",
    "\n",
    "Sex => 性别\n",
    "\n",
    "Age => 年龄\n",
    "\n",
    "SibSp => 堂兄弟/妹个数\n",
    "\n",
    "Parch => 父母与小孩个数\n",
    "\n",
    "Ticket => 船票信息\n",
    "\n",
    "Fare => 票价\n",
    "\n",
    "Cabin => 客舱\n",
    "\n",
    "Embarked => 登船港口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Number of passangers and properties:  (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: \", data_val.columns)\n",
    "print(\"Number of passangers and properties: \", data_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are in total *12* features for each passanger and *891* passanger information available in training data.\n",
    "*Survived* is a binary code to indicate if the passanger survived. This is the target to be predicted for test dataset. \n",
    "But for now, the target doesnt need to be separated, since many operations needed to clean the data first. Do this at last. \n",
    "\n",
    "The data_val is the dataset we need to predict survival on. The transformation done on the train dataset better apply on the evaluation dataset too, to achieve same behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = [data1, data_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>726</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Oreskovic, Mr. Luka</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315094</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>707</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Kelly, Mrs. Florence \"Fannie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223596</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>856</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Aks, Mrs. Sam (Leah Rosen)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>392091</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Foreman, Mr. Benjamin Laventall</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113051</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>C111</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Sigrid Elisabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "725          726         0       3                Oreskovic, Mr. Luka    male   \n",
       "706          707         1       2      Kelly, Mrs. Florence \"Fannie\"  female   \n",
       "855          856         1       3         Aks, Mrs. Sam (Leah Rosen)  female   \n",
       "452          453         0       1    Foreman, Mr. Benjamin Laventall    male   \n",
       "542          543         0       3  Andersson, Miss. Sigrid Elisabeth  female   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
       "725  20.0      0      0  315094   8.6625   NaN        S  \n",
       "706  45.0      0      0  223596  13.5000   NaN        S  \n",
       "855  18.0      0      1  392091   9.3500   NaN        S  \n",
       "452  30.0      0      0  113051  27.7500  C111        C  \n",
       "542  11.0      4      2  347082  31.2750   NaN        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd6e49e5e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1.describe(include = \"all\")\n",
    "data1.Age.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data column are both numerical and object, some need to be transferred, like the Survived, it should be a boolean.\n",
    "There are also lots of missing values(null) in many columns. Explore this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning: Correcting, Completing, Creating, Converting\n",
    "* Correcting: outlier, abnormal data, incorrect data type, .etc\n",
    "* Completing: missing value, null value, .etc, usually using meadian, mean, mode(which count the frequency, return the most frequent one)\n",
    "* Creating: generate new features from the exsting feature.\n",
    "* Converting: datatype formatting, like Data, currency, Boolean, objects, .etc.\n",
    "\n",
    "When making any change to the dataset, compare the result with the original dataset to see if the change worth it. if there is improvement. \n",
    "Backup the data, do not make change on the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many missing value for Cabin 687/891, it may not be usable.\n",
    "The passangerId and Ticket are just random numbers, they should not affect the survival. \n",
    "All three columns can be removed from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop the not useful columns\n",
    "drop_columns = [\"Cabin\", \"Ticket\", \"PassengerId\"]\n",
    "for col in drop_columns:\n",
    "    if(col in data1):\n",
    "        data1.drop(col, inplace=True, axis = 1)\n",
    "print(data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the null/missing values for the remain columns,\n",
    "# for the age, fill na with median value\n",
    "# for the Embarked, fill na with the most comman value\n",
    "# for the Fare, using the median value again. \n",
    "# Do this for the data1 and data_val, to keep the dataset consistance. \n",
    "for dataset in data_clean:\n",
    "    dataset[\"Age\"].fillna(dataset[\"Age\"].median(), inplace = True)\n",
    "    # Embarked are place names, no arithmetical operation allowed. \n",
    "    # mode function counts the unique value frequency, take the most common value. \n",
    "    dataset[\"Embarked\"].fillna(dataset[\"Embarked\"].mode()[0], inplace = True)\n",
    "    \n",
    "    dataset[\"Fare\"].fillna(dataset[\"Fare\"].median(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data1.isnull().sum())\n",
    "print(data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to engineer some new features from the existing feature.\n",
    "1. Family size, how many members are on the cruise. \n",
    "2. If the passenger is alone\n",
    "3. Title, Mr, Miss, .etc. \n",
    "4. Cut age to groups instead of a number \n",
    "Here just to show how feature engineering works, not every new feature make sence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaohuichen/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for dataset in data_clean:\n",
    "    # add the siblings on board with the \n",
    "    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1;\n",
    "    dataset[\"Alone\"] = 1\n",
    "    dataset[\"Alone\"].loc[dataset[\"FamilySize\"] > 1] = 0\n",
    "    dataset[\"Title\"] = dataset[\"Name\"].str.split(\", \", expand = True)[1].str.split(\".\", expand = True)[0]\n",
    "    dataset[\"FareBin\"] = pd.qcut(dataset[\"Fare\"], 4)  # equal cut, every group has same number of elements\n",
    "    dataset[\"AgeBin\"] = pd.cut(dataset[\"Age\"].astype(int), 4) # the span of each group is same, not equal number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Mr\n",
      "dtype: object\n",
      "Mr              False\n",
      "Miss            False\n",
      "Mrs             False\n",
      "Master          False\n",
      "Dr               True\n",
      "Rev              True\n",
      "Col              True\n",
      "Major            True\n",
      "Mlle             True\n",
      "Jonkheer         True\n",
      "Sir              True\n",
      "Ms               True\n",
      "Lady             True\n",
      "the Countess     True\n",
      "Capt             True\n",
      "Mme              True\n",
      "Don              True\n",
      "Name: Title, dtype: bool\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "min_num_title = 10\n",
    "print(data1[\"Title\"].mode())\n",
    "title_names = (data1['Title'].value_counts() < min_num_title) #this will create a true false series with title name as index\n",
    "print(title_names)\n",
    "print(title_names.loc[\"Mr\"])\n",
    "data1[\"Title\"] = data1[\"Title\"].apply(lambda x: \"Misc\" if title_names.loc[x] == True else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        517\n",
       "Miss      182\n",
       "Mrs       125\n",
       "Master     40\n",
       "Misc       27\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the labels to numerical value.\n",
    "Using LabelEncoder from sklearn.preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_transfer = LabelEncoder()\n",
    "data1[\"Sex_Code\"] = label_transfer.fit_transform(data1[\"Sex\"])\n",
    "data1[\"Embarked_Code\"] = label_transfer.fit_transform(data1[\"Embarked\"])\n",
    "data1[\"Title_Code\"] = label_transfer.fit_transform(data1[\"Title\"])\n",
    "data1[\"AgeBin_Code\"] = label_transfer.fit_transform(data1[\"AgeBin\"])\n",
    "data1[\"FareBin_Code\"] = label_transfer.fit_transform(data1[\"FareBin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    646\n",
       "0    168\n",
       "1     77\n",
       "Name: Embarked_Code, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[\"Embarked_Code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X Y:  ['Survived', 'Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] \n",
      "\n",
      "Bin X Y:  ['Survived', 'Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code'] \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['IsAlone'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-2fee2675cd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#define x and y variables for dummy features original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdata1_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata1_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdata1_x_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata1_dummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdata1_xy_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTarget\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata1_x_dummy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['IsAlone'] not in index\""
     ]
    }
   ],
   "source": [
    "Target = ['Survived']\n",
    "\n",
    "#define x variables for original features aka feature selection\n",
    "data1_x = ['Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] #pretty name/values for charts\n",
    "data1_x_calc = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code','SibSp', 'Parch', 'Age', 'Fare'] #coded for algorithm calculation\n",
    "data1_xy =  Target + data1_x\n",
    "print('Original X Y: ', data1_xy, '\\n')\n",
    "\n",
    "\n",
    "#define x variables for original w/bin features to remove continuous variables\n",
    "data1_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\n",
    "data1_xy_bin = Target + data1_x_bin\n",
    "print('Bin X Y: ', data1_xy_bin, '\\n')\n",
    "\n",
    "\n",
    "#define x and y variables for dummy features original\n",
    "data1_dummy = pd.get_dummies(data1[data1_x])\n",
    "data1_x_dummy = data1_dummy.columns.tolist()\n",
    "data1_xy_dummy = Target + data1_x_dummy\n",
    "print('Dummy X Y: ', data1_xy_dummy, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
